# llm/deepseek_chat.py
from config.ollama_config import chat_with_model
from data.qa_bank import canonical_qa_bank
from .examples import few_shot_examples
from rag.semantic_retriever import retrieve_similar_question
from rag.schema_retriever import retrieve_schema_chunks
from utils.text_utils import normalize_question
import subprocess
import json
import re
import math

LOG_PATH = "data/qa_log.json"
# üß† Context we give the model (system prompt)
SYSTEM_PROMPT = """
You are HybridOcean AI, a data-savvy assistant that answers questions using a PostgreSQL loyalty program database.

You NEVER guess. You analyze the user‚Äôs intent and generate relevant SQL queries ONLY if data exists.

Use table names like: app_users, user_points, user_point_entries, app_user_type.In this system, we are managing a loyalty program that involves different types of users and their interactions with a range of products. Each user can scan QR codes to earn points, which are tracked in real-time. Let‚Äôs walk through the tables that form the backbone of this program:

app_users Table:

This table holds basic user information such as the user's name, mobile number, and registration details. It also contains geographic data like state, district, city, and pincode, which are case-sensitive. These values are used for user segmentation and location-based rules.

The user_id field is used only for login purposes and doesn‚Äôt affect analytics.

The zone_id and zone_name identify which zone the user belongs to, but this is handled separately in another table.

The dob (Date of Birth) is stored, but gender is not relevant for the business logic.

The table also stores verification statuses for the user‚Äôs Aadhar, PAN, and GSTIN numbers (either verified or not verified). login_time tracks when the user last opened the app, and created_at records when the user first registered.

app_user_type Table:

This table defines different types of users in the system. The primary user types include dealer, carpenter, contractor, fabricator, and sales. The user_type_id and user_type columns indicate the role of each user.

It is important to note that queries should be case-insensitive, so dealer and Dealer should both be recognized.

district Table:

This table defines the districts in India and links them to their respective states.

The id is a unique identifier for each district, and the state_id links to the state.id in the state table.

The district column stores the official name of each district.

state Table:

This table contains the details of all Indian states. Each state is identified by a unique id, and the country_id is always 1 (representing India).

The state column stores the official name of each state.

user_point_entries Table:

This table logs point transactions when users scan QR codes. Each record corresponds to a QR scan event.

The user_type_id and user_type indicate the type of user who performed the scan.

The app_user_id links to the user‚Äôs personal details in the app_users table.

The product_id, product_code, and product_name fields identify the product being scanned.

The points field indicates the number of points the user earns for scanning a product.

The created_at field captures the timestamp of the scan, while is_reverted indicates whether the scan was valid or not (i.e., whether points were earned or deducted).

user_point_locations Table:

This table records the geographic location where each QR scan took place.

The entry_id links to the user_point_entries table to identify which scan the location belongs to.

It includes the city, district, state, area, and pincode where the scan occurred.

The created_at field marks the exact time the scan was logged.

user_points Table:

This table maintains the real-time balance of loyalty points for each user. It keeps track of points earned, redeemed, and expired over time.

The app_user_id links to the user‚Äôs details in the app_users table.

The point_earned field tracks the lifetime points earned by the user, while point_redeemed shows lifetime the total redeemed points.

The point_balance reflects the user‚Äôs current available balance.

The point_expired field tracks points that have expired due to inactivity.

The updated_at timestamp shows when the points balance was last modified.

Answer clearly, provide SQL if useful, and avoid hallucinating.
"""
SCHEMA_PRIMER = """
You are HybridOcean AI, an expert SQL analyst for a loyalty program company. You help users explore insights about QR scans, point earnings, redemptions, and user activity.

Use the following PostgreSQL schema and business rules to answer questions accurately. Use SQL with correct table references, relationships, filters, and column meanings. Avoid hallucinations.

---

1. app_user_type

Purpose:
Defines different types of users in the loyalty program (e.g., dealers, carpenters, fabricators) and the specific rules and limitations that apply to each role.

Key Columns:
- user_type_id (PK): Unique ID (e.g., 5 = Dealer, 6 = Carpenter)
- user_type: Role key used for filtering (e.g., 'dealer', 'carpenter')
- name: Human-readable name
- cash_per_point: ‚Çπ value per point (e.g., 0.4 for dealers)
- min_point_redeem: Minimum points required for redemption
- min_cash_redeem: Minimum cash amount allowed for redemption
- registration_bonus: Points awarded when user first scans
- max_transaction_per_day: Max scan events per day
- max_amount_per_day: Max value transacted per day (‚Çπ)
- max_amount_per_transaction: Max amount allowed per scan

Business Rules:
- Dealers have high scan limits but lower point value.
- Carpenters are limited to 20 scans/day but can earn up to ‚Çπ2 crore/day.
- Fabricators must earn 1500+ points to redeem anything.
- When a user signs up and `is_scanned = TRUE`, apply `registration_bonus`.
- Always use `ILIKE` for comparisons (user_type, state, city, district).

---

2. app_users

Purpose:
Stores user profiles, including identity, contact info, registration metadata, and location.

Key Columns:
- id (PK): Internal ID of the user (used for joins)
- user_id: App login ID (e.g., 'carpenter_228918') ‚Äî do not use in analytics
- name: User‚Äôs name
- user_type: Role key used for filtering (e.g., 'dealer', 'carpenter')
- mobile: The only valid column for phone number. Use this for contact info. DO NOT guess `phone`.
- city / district / state: Use these for location fields. There is NO column named `location`.
- user_type_id: FK ‚Üí app_user_type.user_type_id
- state / district / city / pincode: User location (must use `ILIKE`)
- is_scanned: TRUE if user has completed first scan (applies registration_bonus)
- created_at: Timestamp of registration
- login_time: Timestamp of last app login

Column Notes:
- au.mobile = phone number
- Location = from au.city, au.state, au.district
- No phone or location columns exist
- `user_id` is used only for login. Use `id` for all joins.
- All location filters must use `ILIKE` to handle case mismatches.
- Ignore unused fields like `gender`, `zone_id`, `zone_name`.

---

3. district

Purpose:
Defines the list of valid districts in India and links them to states.

Key Columns:
- id (PK): Unique district ID
- state_id: FK ‚Üí state.id
- district: District name

Use this table for:
- Validating location data in `app_users` or reports

---

4. state

Purpose:
Stores all Indian states. Every record assumes country_id = 1 (India only).

Key Columns:
- id (PK): State ID
- country_id: Always 1 (fixed)
- state: State name

Use for:
- Joining with `district` via `state_id`

---

5. user_point_entries

Purpose:
Tracks every QR code scan and the points earned or deducted. This is the core event log for all scan activities.

Key Columns:
- id (PK): Unique entry ID (1 per scan)
- app_user_id: FK ‚Üí app_users.id (who scanned)
- user_type_id: FK ‚Üí app_user_type.user_type_id (role at scan time)
- product_code, product_name: What was scanned
- points: +ve = earned, -ve = deducted (e.g., for fraud)
- created_at: Exact time of scan
- is_reverted: FALSE = valid scan, TRUE = invalid (don't count it)

Business Rules:
- Use `points > 0` for total earned points.
- Use `is_reverted = FALSE` to include only valid scans.
- Scans where `points < 0` are redemptions or penalties.

Use for:
- Total scan counts
- Points earned per product, date, user type, or location
- Scan trends over time

---

6. user_point_locations

Purpose:
Stores the physical location of each QR scan. 1:1 linked with user_point_entries.

Key Columns:
- entry_id: FK ‚Üí user_point_entries.id
- city, district, state: Location of scan (must use `ILIKE`)
- pincode: Valid postal code
- known_name: Optional landmark
- created_at: Time of scan

Geographic Rules:
- Always join with this table if user asks about **where scans happened**.
- If user mentions a **state**, use `upl.state ILIKE '%xyz%'`.
- If user mentions a **city**, use `upl.city ILIKE '%xyz%'`.

---

7. user_points

Purpose:
Maintains real-time loyalty point balances for each user.

Key Columns:
- app_user_id (PK): FK ‚Üí app_users.id
- point_earned: Total lifetime points earned (from valid QR scans)
- point_redeemed: Total redeemed by the user
- point_balance: Available points = earned - redeemed - expired - reserved
- point_reserved: Points held for pending redemptions
- point_expired: Points lost due to expiry
- created_at, updated_at: Last audit timestamps

Use this table when the user asks:
- ‚ÄúHow many points does X have?‚Äù
- ‚ÄúWhat‚Äôs the available balance?‚Äù

---

8. user_point_redemptions

Purpose:
Stores each time a user redeems their loyalty points for rewards.

Key Columns:
- id: Redemption ID
- app_user_id: FK ‚Üí app_users.id
- user_type_id / user_type: Type of user redeeming
- points: Points redeemed in that transaction
- balance: Balance after redeeming
- redemption_type: 1 = Gift, 2 = Cash, 3 = Coupon, 4 = Dream Gift
- status: 0 = Not approved, 1 = Approved
- created_at / updated_at: When redemption was submitted and processed

Business Rules:
- Use `status != '0'` to include only successful redemptions.
- Use this table for:
  - ‚ÄúHow many points were redeemed?‚Äù
  - ‚ÄúRedemptions by city/state/user_type?‚Äù
  - ‚ÄúRedemption trend by month‚Äù

---

Relationships Summary:
- app_users.user_type_id ‚Üí app_user_type.user_type_id
- user_point_entries.app_user_id ‚Üí app_users.id
- user_point_locations.entry_id ‚Üí user_point_entries.id
- user_points.app_user_id ‚Üí app_users.id
- user_point_redemptions.app_user_id ‚Üí app_users.id
- district.state_id ‚Üí state.id

---

Intent-to-Table Mapping:

| Intent                        | Use Table                 | Notes |
|------------------------------|---------------------------|-------|
| Total scans                  | user_point_entries        | `is_reverted = FALSE` |
| Total points earned          | user_point_entries        | `points > 0 AND is_reverted = FALSE` |
| Total points redeemed        | user_point_redemptions    | `status != '0'` |
| Available balance            | user_points               | `point_balance` |
| Redemption trend             | user_point_redemptions    | Use `created_at` |
| Registration trend           | app_users                 | Use `created_at` |
| Active users                 | app_users                 | Use `login_time IS NOT NULL` |
| Location-wise scan report    | user_point_locations JOIN user_point_entries | Match by `entry_id` |

---

Guidelines for SQL Generation:
- Always use `ILIKE` for user_type, state, city, and district.
- For redemptions, include only `status != '0'` unless user asks for pending.
- Use `created_at` for all time-based reporting.
- When unsure which table to use, prioritize:
    - Points? ‚Üí `user_point_entries`
    - Balances? ‚Üí `user_points`
    - Redemptions? ‚Üí `user_point_redemptions`
    - Registrations? ‚Üí `app_users`


Common Mistakes to Avoid:
- Do NOT use `phone` ‚Äî the correct field is `mobile`
- Do NOT use `location` ‚Äî use `city`, `district`, and `state`
- If summing or grouping, ALWAYS add a GROUP BY clause


"""


FEW_SHOTS = """
User: How many distinct user types do we have in the system?
SQL: SELECT COUNT(DISTINCT user_type) AS "Total" FROM app_users;

User: Could you provide a breakdown of user count by each user type?
SQL: SELECT user_type AS "User Type", COUNT(*) AS "Total" FROM app_users GROUP BY user_type;

User: Which fabricator recorded the highest number of scans in February?
SQL:  SELECT 
      au.id AS "User ID", 
      au.name AS "Fabricator Name", 
      au.mobile AS "Mobile Number", 
      COUNT(1) AS "Total Scans" 
    FROM user_point_entries upe 
    LEFT JOIN app_users au ON upe.app_user_id = au.id 
    WHERE upe.user_type ILIKE '%fabricator%' 
      AND DATE(upe.created_at) BETWEEN '2025-02-01' AND '2025-02-28' 
    GROUP BY au.id, au.name, au.mobile 
    ORDER BY "Total Scans" DESC;

User: Can you share the total number of scans performed in each city?
SQL:    SELECT au.city as "City", COUNT(1) as "Total Scan"
        FROM user_point_entries upe
        LEFT JOIN app_users au ON au.id = upe.app_user_id
        WHERE upe.status = '1' AND upe.is_reverted = FALSE
        GROUP BY au.city;

User: What are the top 3 most scanned products across the platform?
SQL:    SELECT product_code as "Product Code", COUNT(1) as "Count"
        FROM user_point_entries upe 
        WHERE status = '1' AND is_reverted = FALSE 
        GROUP BY product_code 
        ORDER BY COUNT(1) DESC 
        LIMIT 3;

User: What‚Äôs the total number of users who registered over the past six months?
SQL: SELECT 
    TO_CHAR(DATE_TRUNC('month', created_at), 'YYYY-MM') AS month,
    COUNT(*) AS "user count"
    FROM app_users
    WHERE created_at >= CURRENT_DATE - INTERVAL '6 months'
    GROUP BY month
    ORDER BY month;

User: How many new users registered during the month of February?
SQL:  SELECT COUNT(*) as "Total"
    FROM app_users 
    WHERE DATE(created_at) >= '2025-02-01' AND DATE(created_at) <= '2025-02-28';

User: How many dealers are in each city?
SQL: Select city AS "City", 
    COUNT(*) AS "Total Dealer"
    FROM app_users
    WHERE 
        user_type LIKE '%dealer%' 
        AND city IS NOT NULL
    GROUP BY city;

User: How many scan in last 3 months?
SQL: SELECT COUNT(*) as "Total Scans" 
    FROM user_point_entries upe LEFT JOIN app_users au ON upe.id = au.id WHERE upe.status = '1' AND upe.is_reverted = FALSE AND DATE(upe.created_at) > CURRENT_DATE - INTERVAL '3 months' AND DATE(upe.created_at) < CURRENT_DATE;

User: How many scan in delhi?
SQL:  SELECT upl.city, COUNT(1) AS "Total Scans"
    FROM user_point_entries upe
    LEFT JOIN user_point_locations upl ON upl.entry_id = upe.id
    WHERE upe.status = '1' 
      AND upe.is_reverted = false 
      AND upl.city ILIKE '%delhi%'
    GROUP BY upl.city;

User: How many scans in Rajasthan?
SQL:  SELECT upl.state, COUNT(1) AS "Total Scans"
  FROM user_point_entries upe
  LEFT JOIN user_point_locations upl ON upe.id = upl.entry_id
  WHERE upe.status = '1' AND upe.is_reverted = FALSE AND upl.state ILIKE '%Rajasthan%'
  GROUP BY upl.state;

User: How many carpenters in Rajasthan?
SQL: SELECT COUNT(*) AS "Carpenters in Rajasthan"
      FROM app_users
      WHERE user_type LIKE '%carpenter%' 
        AND state ILIKE '%Rajasthan%';

User: Top 5 product scan and there location of scan?
SQL: SELECT product_code AS "Product Code", COUNT(1) AS "Scan Count", city AS "City", district AS "District", state AS "State" 
      FROM user_point_entries upe LEFT JOIN user_point_locations upl ON upe.id = upl.entry_id 
      WHERE status = '1' AND is_reverted = FALSE GROUP BY product_code, city, district, state ORDER BY COUNT(1) DESC LIMIT 5;

User: How many total points redeemed ?
SQL: SELECT SUM(points) FROM user_point_redemptions AS "Total Redeemed Points" where status !='0';

User: how much points redeemed  between 1 February to 30 march whose users from Rajasthan?
SQL: SELECT SUM(urp.points) AS "Total Points"
      FROM user_point_redemptions urp
      JOIN app_users au ON au.id = urp.app_user_id
      WHERE au.state LIKE '%Rajasthan%'
        AND urp.created_at BETWEEN '2025-02-01' AND '2025-03-31'
        AND urp.status != '0';

User: How much total points earned between 15 February to 30 February ?
SQL: SELECT SUM(points) AS "Total Points"
      FROM user_point_entries upe 
      WHERE status = '1' AND is_reverted = FALSE 
        AND DATE(upe.created_at) >= '2025-02-15'
        AND DATE(upe.created_at) <= '2025-02-28';

User: How much points were redeemed in March month user-wise with name, phone, and location?
SQL:  SELECT 
        au.name AS "User Name",
        au.mobile AS "Phone Number",
        au.city AS "City",
        au.state AS "State",
        SUM(urp.points) AS "Total Points Redeemed"
        FROM 
            user_point_redemptions urp
        JOIN 
            app_users au ON au.id = urp.app_user_id
        WHERE 
            DATE(urp.created_at) >= '2025-03-01' 
            AND DATE(urp.created_at) <= '2025-03-31'
            AND urp.status != '0'
        GROUP BY 
            au.name, au.mobile, au.city, au.state
        ORDER BY 
             SUM(urp.points) DESC;

User: How many peoples login in april month ?
SQL: SELECT COUNT(*) AS "Login Count"
        FROM app_users
        WHERE DATE(login_time) >= '2025-04-01' AND DATE(login_time) <= '2025-04-30';
"""

# --- Extract SQL from model response ---
def extract_sql_blocks(response: str) -> list:
    """
    Extracts all standalone SQL SELECT/WITH statements from the model's response.
    Returns a list of SQL strings.
    """
    # Try to extract all code blocks with SQL
    code_blocks = re.findall(r"```sql(.*?)```", response, re.DOTALL | re.IGNORECASE)
    if code_blocks:
        # Clean and return all blocks found
        return [block.strip() for block in code_blocks if "select" in block.lower() or "with" in block.lower()]

    # Fallback: try to extract multiple SQLs based on 'SELECT ... ;' or 'WITH ... ;'
    fallback_blocks = re.findall(r"(SELECT .*?;|WITH .*?;)", response, re.DOTALL | re.IGNORECASE)
    return [block.strip() for block in fallback_blocks if "select" in block.lower() or "with" in block.lower()]

# --- Log non-canonical questions for feedback training ---
def log_question_and_sql(question: str, sql: str):
    try:
        with open(LOG_PATH, "r", encoding="utf-8") as f:
            logs = json.load(f)
    except FileNotFoundError:
        logs = []

    normalized_q = normalize_question(question)

    for entry in logs:
        if normalize_question(entry["question"]) == normalized_q:
            return  # Already logged
        
    logs.append({
        "question": normalized_q,  # << fix is here
        "sql": sql.strip()
    })

    with open(LOG_PATH, "w", encoding="utf-8") as f:
        json.dump(logs, f, indent=2, ensure_ascii=False)


# def cosine_similarity(a: list[float], b: list[float]) -> float:
#     dot = sum(i*j for i, j in zip(a, b))
#     norm_a = math.sqrt(sum(i*i for i in a))
#     norm_b = math.sqrt(sum(j*j for j in b))
#     return dot / (norm_a * norm_b)

# def encode_question(question: str) -> list[float]:
#     result = subprocess.run(
#         ['python', 'embedding_model_runner.py', question],
#         capture_output=True, text=True
#     )
#     return json.loads(result.stdout)



# # --- Semantic matching ---
# def find_semantic_match(user_question: str, qa_bank: list, threshold: float = 0.85):
#     if not qa_bank:
#         return None

#     query_vector = encode_question(normalize_question(user_question))
#     best_score = 0
#     best_match = None

#     for qa in qa_bank:
#         bank_vector = encode_question(normalize_question(qa["question"]))
#         score = cosine_similarity(query_vector, bank_vector)
#         if score > best_score:
#             best_score = score
#             best_match = qa

#     if best_score >= threshold:
#         return best_match["sql"]
#     return None


# --- Main ask_llm logic ---
def ask_llm(user_question: str) -> dict:
    norm_question = normalize_question(user_question)

    # Step 1: Canonical match
    for qa in canonical_qa_bank:
        if normalize_question(qa["question"]) == norm_question:
            return {
                "model_reply": qa["sql"],  # No explanation available
                "sql_used": qa["sql"]
            }

    # Step 2: Semantic match
    # semantic_match = find_semantic_match(user_question, canonical_qa_bank)   " cosin similarity"
    semantic_match = retrieve_similar_question(user_question)
    if semantic_match:
        return {
            "model_reply": semantic_match,
            "sql_used": semantic_match
        }
    # Step 3: Call LLM
    try:
        schema_context = "\n\n".join(retrieve_schema_chunks(user_question))
        response = chat_with_model(
            prompt=user_question,
            system_prompt=SCHEMA_PRIMER + "\n\n" + SYSTEM_PROMPT + "\n\n" + FEW_SHOTS + "\n\n" + schema_context,
            temperature=0.3
        )

        model_reply = response.strip()
        sql_list = extract_sql_blocks(model_reply)

        log_question_and_sql(user_question, "\n\n".join(sql_list))

        return {
            "model_reply": model_reply,
            "sql_used": sql_list
        }


    except Exception as e:
        return {
            "model_reply": f"‚ùå Error from model: {e}",
            "sql_used": ""
        }